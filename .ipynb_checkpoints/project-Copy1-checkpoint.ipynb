{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763d2238-35cd-4998-bb8f-7c907af6818c",
   "metadata": {},
   "source": [
    "## MASSIVE ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12e9da-54f1-4dd0-bfbc-9682eaae02f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a2f9470-ba56-462f-9829-388832253f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec451398-739e-49be-8a9a-e76f18bdaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['KAGGLE_USERNAME'] = \"melissarizzi\"\n",
    "#os.environ['KAGGLE_KEY'] = \"3ed913e7329a3117a254e67179c0f8bb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e692ed4-ac60-4982-90dc-48ab6dd3797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kaggle) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\angel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d6b5c9-0837-4d38-a26c-7afc7acdf129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
      "License(s): CC0-1.0\n",
      "amazon-books-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "#!kaggle datasets download -d mohamedbakhet/amazon-books-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6576e7-9231-41bf-b56e-eb4c073650dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with zipfile.ZipFile(\"amazon-books-reviews.zip\", 'r') as zip_ref:\n",
    "#    zip_ref.extractall(\"amazon_books_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f666223-9b9b-48fb-b264-9e895cddc5d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d74c0e1a-f2cb-4106-85fb-b23b3e66cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb68e57-e5af-4df6-ad14-a1478a1d4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"amazon_books_data/Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2577fe-48e9-4438-b9b6-6f345345a2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Id                  object \n",
      " 1   Title               object \n",
      " 2   Price               float64\n",
      " 3   User_id             object \n",
      " 4   profileName         object \n",
      " 5   review/helpfulness  object \n",
      " 6   review/score        float64\n",
      " 7   review/time         int64  \n",
      " 8   review/summary      object \n",
      " 9   review/text         object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 228.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types to verify integrity of data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d0aee80-6b5f-4a9d-96e7-2793ce81d43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# Check review/score range\n",
    "min_value = data['review/score'].min()\n",
    "print(min_value)\n",
    "max_value = data['review/score'].max()\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d0dae-70bf-4dd0-86b6-16476d0bd38c",
   "metadata": {},
   "source": [
    "All rating scores are in the correct range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5f4fc4a-bb4c-495e-832d-94b8853dfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless variables\n",
    "df = data.drop(['Price', 'profileName', 'review/helpfulness', 'review/time'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08756362-f43e-4b8a-803f-54f122b812ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title         User_id  review/score  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!   AVCGYZL8FQQTD           4.0   \n",
       "1  0826414346        Dr. Seuss: American Icon  A30TK6U7DNS82R           5.0   \n",
       "2  0826414346        Dr. Seuss: American Icon  A3UH4UZ4RSVO82           5.0   \n",
       "3  0826414346        Dr. Seuss: American Icon  A2MVUWT453QH61           4.0   \n",
       "4  0826414346        Dr. Seuss: American Icon  A22X4XUPKF66MR           4.0   \n",
       "\n",
       "                                    review/summary  \\\n",
       "0           Nice collection of Julie Strain images   \n",
       "1                                Really Enjoyed It   \n",
       "2  Essential for every personal and Public Library   \n",
       "3  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d1899-4dea-41f1-ac47-5a885e93d370",
   "metadata": {},
   "source": [
    "#### 2.1 Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "178c2f35-40a7-4a64-9e64-11634befd3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                     0\n",
       "Title                208\n",
       "User_id           561787\n",
       "review/score           0\n",
       "review/summary       407\n",
       "review/text            8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd56cd-47dd-454c-8222-1b69d34c40c0",
   "metadata": {},
   "source": [
    "What stands out right away, especially for the purpose of our analysis, is that there are many missing values in the User_id variable. One possible reason for this could be that users who leave reviews but are not registered don’t have a user ID. Our goal is to identify baskets of items purchased by the same users, but without the user ID, this analysis cannot be conducted. We explored the possibility of using profile names instead, by assigning a dummy ID to users with the same name. However, we were aware that this might not provide accurate results due to potential name duplication. Moreover, there were more missing profile names than missing user IDs, which made this solution unfeasible. After considering our options, we ultimately decided to **drop the missing values**, as we couldn’t identify a suitable method to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e37a58a-e391-4e32-93ea-b423cd16bf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0\n",
       "Title             0\n",
       "User_id           0\n",
       "review/score      0\n",
       "review/summary    0\n",
       "review/text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "# Check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "792236e6-bcae-4999-9c02-3a79a618e555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2437620, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset shape after null values removal \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eca9a-a340-44b9-8721-8f50635c574f",
   "metadata": {},
   "source": [
    "#### 2.2 Data Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b58a5aca-1373-48a0-825a-1fc589a19843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(17544)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numbers of rows with the same value for all the variables\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fe7e995-2b97-4072-8188-d987ad45ac8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "# Check\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61146345-66ac-41fc-9b22-78cad2335a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420076, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset shape after null values removal \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8a113-16f5-4ab7-a08d-38ebc3257acb",
   "metadata": {},
   "source": [
    "Up until now, we’ve performed a general cleaning of the dataset. From here on, we’ll focus exclusively on the three columns that are relevant to our analysis (Id, User_id, and review/score), forming a new dataset: df_short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bd6df60-8224-4062-8083-f351ae6564c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "df_short = df.drop(['Title', 'review/text', 'review/summary'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5600280e-a6c5-4e8f-85ac-89c8ce0697b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id         User_id  review/score\n",
       "0  1882931173   AVCGYZL8FQQTD           4.0\n",
       "1  0826414346  A30TK6U7DNS82R           5.0\n",
       "2  0826414346  A3UH4UZ4RSVO82           5.0\n",
       "3  0826414346  A2MVUWT453QH61           4.0\n",
       "4  0826414346  A22X4XUPKF66MR           4.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36ce2b8f-8fea-4242-bfcd-79b4c2cf08d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37049, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicated rows for the three considered variables\n",
    "df_duplicati = df_short[df_short.duplicated(keep=False)]\n",
    "df_duplicati.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b39135dd-190f-48b4-8f7c-7d7ddf94875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(19996)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count just the duplicated rows\n",
    "df_short.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6322be7-3f5a-4110-be29-bc90c3fa3239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicated rows\n",
    "df_short = df_short.drop_duplicates()\n",
    "# Check\n",
    "df_short.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7088e5e5-defb-4e04-a380-8ba5402126d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6020, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicates just for the varibales Id, User_id, to verify if there are 2 reviews from the same user but with different score\n",
    "duplicati = df_short[df_short.duplicated(subset=['Id', 'User_id'], keep=False)]\n",
    "duplicati.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c88baa46-fc8b-4fcb-b10e-31c5b24438b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>User_id</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id         User_id  mean_score\n",
       "0  1882931173   AVCGYZL8FQQTD         4.0\n",
       "1  0826414346  A30TK6U7DNS82R         5.0\n",
       "2  0826414346  A3UH4UZ4RSVO82         5.0\n",
       "3  0826414346  A2MVUWT453QH61         4.0\n",
       "4  0826414346  A22X4XUPKF66MR         4.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean of the different score given by the same user to the same item\n",
    "score_mean = df_short.groupby(['Id', 'User_id'])['review/score'].mean()\n",
    "df_final = pd.merge(df_short, score_mean, on=['Id', 'User_id'], how='left', suffixes=('', '_mean'))\n",
    "df_final = df_final.drop(columns=['review/score'])\n",
    "df_final = df_final.rename(columns={'review/score_mean': 'mean_score'})\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed0223ad-8db4-4722-8b3d-7d125d66d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3059)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of duplicats\n",
    "df_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d4287f6-d6fc-4954-9e8b-d293d612a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicated values\n",
    "df_final = df_final.drop_duplicates()\n",
    "# Check\n",
    "df_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "683d2105-01ec-4f6f-9135-acf378c379ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2397021, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape after duplicated values removal\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433c56b-d689-47f5-9909-fef27f4ccb77",
   "metadata": {},
   "source": [
    "#### 2.3 Rating means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc304d-8f56-4051-815d-49ff13645eb9",
   "metadata": {},
   "source": [
    "We want to calculate the average score for each book (Id) to see if consistency is maintained after creating the subsample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d55063-645d-49bf-a292-18707abbb343",
   "metadata": {},
   "source": [
    "- Overall mean score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccb49466-1c8b-4551-9b75-a46c0413facf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.224974527409926\n"
     ]
    }
   ],
   "source": [
    "overall_mean_score = df_final['mean_score'].mean()\n",
    "print(overall_mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacaa7a-69df-4f0f-b974-35e01a859238",
   "metadata": {},
   "source": [
    "- Mean score for each item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f15ee7b1-229d-4201-b05d-f164604ce7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Id  mean_score\n",
      "0       0001047604    3.000000\n",
      "1       0001047655    3.725806\n",
      "2       0001047736    3.500000\n",
      "3       0001047825    4.041667\n",
      "4       0001047876    4.000000\n",
      "...            ...         ...\n",
      "216004  B002PWLQ04    5.000000\n",
      "216005  B0030EY97I    3.000000\n",
      "216006  B003IMNND8    3.700000\n",
      "216007  B005MX54HO    4.597561\n",
      "216008  B0064P287I    4.475904\n",
      "\n",
      "[216009 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mean_scores = df_final.groupby('Id')['mean_score'].mean().reset_index()\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae857ed-c62d-4230-9683-ddad329e0bdf",
   "metadata": {},
   "source": [
    "### 3. Reasonable Subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf2c11e-1cac-4b3a-bd57-5ba6ccf64dd4",
   "metadata": {},
   "source": [
    "We want to create a reasonable subsample that is representative of the original dataset, but with lower computational costs. To do so, we use MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "581971cb-320a-4ea4-a202-019df860642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysparkNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pyspark-3.5.5.tar.gz (317.2 MB)\n",
      "     ---------------------------------------- 0.0/317.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 3.9/317.2 MB 29.4 MB/s eta 0:00:11\n",
      "     - ------------------------------------ 11.8/317.2 MB 32.0 MB/s eta 0:00:10\n",
      "     -- ----------------------------------- 19.7/317.2 MB 34.5 MB/s eta 0:00:09\n",
      "     --- ---------------------------------- 27.3/317.2 MB 34.5 MB/s eta 0:00:09\n",
      "     ---- --------------------------------- 35.1/317.2 MB 35.4 MB/s eta 0:00:08\n",
      "     ----- -------------------------------- 43.3/317.2 MB 35.7 MB/s eta 0:00:08\n",
      "     ------ ------------------------------- 51.1/317.2 MB 35.8 MB/s eta 0:00:08\n",
      "     ------- ------------------------------ 58.5/317.2 MB 35.8 MB/s eta 0:00:08\n",
      "     ------- ------------------------------ 64.7/317.2 MB 35.0 MB/s eta 0:00:08\n",
      "     -------- ----------------------------- 71.8/317.2 MB 34.7 MB/s eta 0:00:08\n",
      "     --------- ---------------------------- 80.0/317.2 MB 34.9 MB/s eta 0:00:07\n",
      "     ---------- --------------------------- 87.8/317.2 MB 35.2 MB/s eta 0:00:07\n",
      "     ---------- --------------------------- 90.7/317.2 MB 33.4 MB/s eta 0:00:07\n",
      "     ----------- ------------------------- 100.7/317.2 MB 34.4 MB/s eta 0:00:07\n",
      "     ------------ ------------------------ 109.8/317.2 MB 34.5 MB/s eta 0:00:07\n",
      "     ------------- ----------------------- 119.0/317.2 MB 35.2 MB/s eta 0:00:06\n",
      "     -------------- ---------------------- 127.7/317.2 MB 35.4 MB/s eta 0:00:06\n",
      "     --------------- --------------------- 137.1/317.2 MB 35.9 MB/s eta 0:00:06\n",
      "     ----------------- ------------------- 145.8/317.2 MB 36.1 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 154.4/317.2 MB 36.4 MB/s eta 0:00:05\n",
      "     ------------------ ------------------ 162.8/317.2 MB 36.5 MB/s eta 0:00:05\n",
      "     -------------------- ---------------- 171.7/317.2 MB 36.7 MB/s eta 0:00:04\n",
      "     --------------------- --------------- 180.6/317.2 MB 36.9 MB/s eta 0:00:04\n",
      "     ---------------------- -------------- 189.5/317.2 MB 37.2 MB/s eta 0:00:04\n",
      "     ----------------------- ------------- 198.2/317.2 MB 37.3 MB/s eta 0:00:04\n",
      "     ------------------------ ------------ 206.3/317.2 MB 37.4 MB/s eta 0:00:03\n",
      "     ------------------------ ------------ 213.4/317.2 MB 37.2 MB/s eta 0:00:03\n",
      "     ------------------------- ----------- 220.5/317.2 MB 36.9 MB/s eta 0:00:03\n",
      "     -------------------------- ---------- 229.1/317.2 MB 37.1 MB/s eta 0:00:03\n",
      "     --------------------------- --------- 238.3/317.2 MB 37.2 MB/s eta 0:00:03\n",
      "     ---------------------------- -------- 246.7/317.2 MB 37.4 MB/s eta 0:00:02\n",
      "     ----------------------------- ------- 255.9/317.2 MB 37.4 MB/s eta 0:00:02\n",
      "     ------------------------------ ------ 264.2/317.2 MB 37.7 MB/s eta 0:00:02\n",
      "     ------------------------------- ----- 273.2/317.2 MB 37.9 MB/s eta 0:00:02\n",
      "     -------------------------------- ---- 282.1/317.2 MB 38.0 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 290.7/317.2 MB 38.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 299.6/317.2 MB 38.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 307.0/317.2 MB 38.2 MB/s eta 0:00:01\n",
      "     ------------------------------------  316.1/317.2 MB 38.3 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.2 MB 38.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.2 MB 38.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.2 MB 38.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.2 MB 38.4 MB/s eta 0:00:01\n",
      "     ------------------------------------  317.2/317.2 MB 38.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- 317.2/317.2 MB 33.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (pyproject.toml): started\n",
      "  Building wheel for pyspark (pyproject.toml): still running...\n",
      "  Building wheel for pyspark (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.5-py2.py3-none-any.whl size=317747965 sha256=739cabcea3def180b15d6f4e884c514834e2ffd7a5605bc56f96181b5a428b25\n",
      "  Stored in directory: c:\\users\\angel\\appdata\\local\\pip\\cache\\wheels\\8f\\cb\\c0\\cc57eb1bf0f9dc87cdaf2b0dbac49e58a210ff68d21d6fc709\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.5\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a81d7d7-9189-4754-84bd-150e46395920",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Creazione della SparkSession\u001b[39;00m\n\u001b[0;32m      5\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSubsampleBooks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[2]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Check \u001b[39;00m\n\u001b[0;32m     11\u001b[0m spark\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\java_gateway.py:104\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 104\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Useful libraries \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Creazione della SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SubsampleBooks\") \\\n",
    "    .master(\"local[2]\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Check \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a0780-9972-4515-a279-66e64f567266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame in a Spark DataFrame\n",
    "df_final_spark = spark.createDataFrame(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad2a00-1031-4c43-af07-724f1a5acfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible Subsample\n",
    "sampling_rate = 0.08\n",
    "seed_value = 42\n",
    "df_sampled = df_final_spark.sample(fraction=sampling_rate, withReplacement=False, seed=seed_value)\n",
    "\n",
    "df_sampled.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
