{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d6d54f-dae5-43b3-ad40-b7b201bd17d5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d2238-35cd-4998-bb8f-7c907af6818c",
   "metadata": {},
   "source": [
    "# MARKET-BASKET ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d58f04-d2e4-4e30-b041-e04f5ca4abeb",
   "metadata": {},
   "source": [
    "## Massive Algorithm \n",
    "### Data Science for Economics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30d303-7b2d-4f77-9f60-7dfda5adc634",
   "metadata": {},
   "source": [
    "##### Angelica Longo, Melissa Rizzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758f691-8d9b-44be-84c5-4e58d70505f3",
   "metadata": {},
   "source": [
    "The goal of this project is to implement a system for **detecting frequent itemsets**, commonly known as **market-basket analysis**.\n",
    "In this notebook, the detector treats each user’s reviewed books as a basket, with books serving as items.\n",
    "\n",
    "The project is based on the **[Amazon Books Review](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews)** dataset, published on Kaggle under the public domain CC0 license. Data is downloaded during the execution of the scripts via an API and contains variables related to users and their reviews of purchased books.\n",
    "\n",
    "Given the large volume of data (3 million rows), a reasonable subsample is created using **PySpark**, consisting of approximately 500,000 rows, while ensuring scalability for the full dataset.\n",
    "\n",
    "The project is structured as follows:\n",
    "\n",
    "- **Preprocessing** – This phase includes data cleaning, checking data integrity, handling null values, removing duplicates, and computing the overall mean to verify consistency with the selected subsample.\n",
    "- **Subsampling** – A subset of data is created while maintaining a representative distribution of user choices and ratings.\n",
    "- **Frequent Itemset Mining** – The final step involves implementing an algorithm to identify frequent itemsets within the dataset.\n",
    "\n",
    "This structured approach ensures both **efficiency** and **scalability** while maintaining **data integrity**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731e154-e05f-47b4-8401-fbf00ac84f77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Table of Contents\n",
    "- [1. Data Import](#1-Data-Import)\n",
    "- [2. Data PreProcessing](#2-data-preprocessing)\n",
    "  - [2.1 Data Integrity](#21-data-integrity)\n",
    "  - [2.2 Missing Data](#22-missing-data)\n",
    "  - [2.3 Data Duplicates](#22-data-duplicates)\n",
    "  - [2.4 Rating Means](#22-rating-means)\n",
    "- [3. Subsample Creation](#3-subsample-creation)\n",
    "- [4. Frequent Itemset Mining](#4-frequent-itemset-mining)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12e9da-54f1-4dd0-bfbc-9682eaae02f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "### 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2f9470-ba56-462f-9829-388832253f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec451398-739e-49be-8a9a-e76f18bdaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['KAGGLE_USERNAME'] = \"melissarizzi\"\n",
    "#os.environ['KAGGLE_KEY'] = \"3ed913e7329a3117a254e67179c0f8bb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e692ed4-ac60-4982-90dc-48ab6dd3797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d6b5c9-0837-4d38-a26c-7afc7acdf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d mohamedbakhet/amazon-books-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6576e7-9231-41bf-b56e-eb4c073650dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with zipfile.ZipFile(\"amazon-books-reviews.zip\", 'r') as zip_ref:\n",
    "#    zip_ref.extractall(\"amazon_books_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f666223-9b9b-48fb-b264-9e895cddc5d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "### 2. Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8516ec6a-2fc2-45db-8a19-29787ca5437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, min, max, sum, when\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fedb1a1-5a11-482a-982a-e2b4794efee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"MapReduce\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4170ba-faf9-427d-8cd6-37d6e11af3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = spark.read.csv(\"amazon_books_data/Books_rating.csv\", header=True, inferSchema=True)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89825f6b-49b7-441f-99f4-b6c2e8312289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only useful columns\n",
    "df = data.select(\"Id\", 'Title', \"User_id\", \"review/score\",'review/text').withColumnRenamed(\"review/score\", \"score\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a5990-8e66-46ba-b901-e2512c7588e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.1 Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aba7801-26bb-4ede-b4e0-9d8b86872faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b338f85d-630b-4d4f-8bc8-2c0d7bc843c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform 'score' variable in double type\n",
    "df = df.withColumn(\"score\", col(\"score\").cast(DoubleType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f19f6eb-d07a-488c-a051-daec53e43aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|min_score| max_score|\n",
      "+---------+----------+\n",
      "|      1.0|1.295568E9|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check score range\n",
    "df.select(min(col(\"score\")).alias(\"min_score\"), max(col(\"score\")).alias(\"max_score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e6c255-85cf-4bcb-a75d-3bcbd8a65d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      score|\n",
      "+-----------+\n",
      "|        1.0|\n",
      "|        4.0|\n",
      "|      19.95|\n",
      "|       NULL|\n",
      "|        3.0|\n",
      "|        2.0|\n",
      "|        5.0|\n",
      "|      327.0|\n",
      "| 1.295568E9|\n",
      "|1.2089952E9|\n",
      "|  1.21176E9|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"score\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55593ded-7fa4-402a-b75c-e813567c3987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min_score|max_score|\n",
      "+---------+---------+\n",
      "|      1.0|      5.0|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep just data with the 'score' values in the correct range [1, 5]\n",
    "df = df.filter((col(\"score\") >= 1) & (col(\"score\") <= 5))\n",
    "df.select(min(\"score\").alias(\"min_score\"), max(\"score\").alias(\"max_score\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d1899-4dea-41f1-ac47-5a885e93d370",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.2 Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "696f1305-282a-48ed-823a-eb518e19d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+-----+-----------+\n",
      "| Id|Title|User_id|score|review/text|\n",
      "+---+-----+-------+-----+-----------+\n",
      "|  0|  196| 561492|    0|          9|\n",
      "+---+-----+-------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null values for each variable\n",
    "null_counts = df.select(\n",
    "    [sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns]\n",
    ")\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd56cd-47dd-454c-8222-1b69d34c40c0",
   "metadata": {},
   "source": [
    "What stands out right away, especially for the purpose of our analysis, is that there are many missing values in the User_id variable. One possible reason for this could be that users who leave reviews but are not registered don’t have a user ID. Our goal is to identify baskets of items purchased by the same users, but without the user ID, this analysis cannot be conducted. We explored the possibility of using profile names instead, by assigning a dummy ID to users with the same name. However, we were aware that this might not provide accurate results due to potential name duplication. Moreover, there were more missing profile names than missing user IDs, which made this solution unfeasible. After considering our options, we ultimately decided to **drop the missing values**, as we couldn’t identify a suitable method to replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178c2f35-40a7-4a64-9e64-11634befd3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------+-----+--------------------+\n",
      "|        Id|               Title|       User_id|score|         review/text|\n",
      "+----------+--------------------+--------------+-----+--------------------+\n",
      "|1882931173|Its Only Art If I...| AVCGYZL8FQQTD|  4.0|This is only for ...|\n",
      "|0826414346|Dr. Seuss: Americ...|A30TK6U7DNS82R|  5.0|I don't care much...|\n",
      "|0826414346|Dr. Seuss: Americ...|A3UH4UZ4RSVO82|  5.0|\"If people become...|\n",
      "|0826414346|Dr. Seuss: Americ...|A2MVUWT453QH61|  4.0|Theodore Seuss Ge...|\n",
      "|0826414346|Dr. Seuss: Americ...|A22X4XUPKF66MR|  4.0|\"Philip Nel - Dr....|\n",
      "+----------+--------------------+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove null values\n",
    "df_clean = df.dropna()\n",
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "792236e6-bcae-4999-9c02-3a79a618e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows - Before cleaning: 2981912\n",
      "Number of Rows - After cleaning: 2420235\n"
     ]
    }
   ],
   "source": [
    "# Check data size\n",
    "n_rows = df.count()\n",
    "n_rows_clean = df_clean.count()\n",
    "print(f\"Number of Rows - Before cleaning: {n_rows}\")\n",
    "print(f\"Number of Rows - After cleaning: {n_rows_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eca9a-a340-44b9-8721-8f50635c574f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.3 Data Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58a5aca-1373-48a0-825a-1fc589a19843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows- after duplicates removal: 2398220\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated rows\n",
    "df_clean = df_clean.dropDuplicates()\n",
    "\n",
    "n_rows_clean = df_clean.count()\n",
    "print(f\"Number of Rows - After duplicates removal: {n_rows_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8a113-16f5-4ab7-a08d-38ebc3257acb",
   "metadata": {},
   "source": [
    "Up until now, we’ve performed a general cleaning of the dataset. From here on, we’ll focus exclusively on the three columns that are relevant to our analysis (Id, User_id, and score), forming a new dataset: df_short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd6df60-8224-4062-8083-f351ae6564c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless columns\n",
    "df_short = df_clean.select(\"Id\", \"User_id\",\"score\")\n",
    "df_short.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ce2b8f-8fea-4242-bfcd-79b4c2cf08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and remove duplicated rows for the three considered variables\n",
    "df_short= df_short.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e30303-5bc3-4aa8-a1f4-3b0aeb9a757f",
   "metadata": {},
   "source": [
    "Given that the same user could have rated the same book twice, we want to compute the mean of the different scores given by the same user to the same book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7088e5e5-defb-4e04-a380-8ba5402126d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----+\n",
      "|        Id|       User_id|count|\n",
      "+----------+--------------+-----+\n",
      "|0451518713|A2TZZQUHX0PVN4|    2|\n",
      "|B000K0DB8I|A2OJH3S0SUNVGE|    2|\n",
      "|B000Q56SO6|A23LDF7TIIKTCY|    2|\n",
      "|B000GSKM2M|A1RJD10TTI568L|    2|\n",
      "|B0006W43TQ| A81F0YW06W5VQ|    2|\n",
      "+----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find duplicates considering only 'Id' and 'User_id'\n",
    "duplicati = df_short.groupBy(\"Id\", \"User_id\").count().filter(\"count > 1\")\n",
    "duplicati.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4695327d-85fe-4038-a0c8-3692f2dd5524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----+----------+\n",
      "|        Id|       User_id|score|mean_score|\n",
      "+----------+--------------+-----+----------+\n",
      "|1597400602|A3DKP67DK28RUB|  5.0|       5.0|\n",
      "|B0007H4QBK|A3MVU8X8EC9VRT|  5.0|       5.0|\n",
      "|B0007H4QBK| AFP82QXWXAG2V|  5.0|       5.0|\n",
      "|B000MCKQRS|A1TQL7XMTVF4JG|  3.0|       3.0|\n",
      "|B000O3QCH8|A1T97PDD7JYCUA|  1.0|       1.0|\n",
      "+----------+--------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute average score for every (Id, User_id)\n",
    "score_mean = df_short.groupBy('Id', 'User_id').agg(F.mean('score').alias('mean_score'))\n",
    "\n",
    "df_final = df_short.join(score_mean, on=['Id', 'User_id'], how='left')\n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e6f1cb8-b266-40e3-acc3-1eb27016eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the final preprocessed dataset\n",
    "df_final = df_final.select('Id','User_id', 'mean_score')\n",
    "df_final = df_final.dropDuplicates()\n",
    "df_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff19bedb-5e69-46f1-9d61-06d2f882e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows - Final dataset: 2380153\n"
     ]
    }
   ],
   "source": [
    "n_rows_final = df_final.count()\n",
    "print(f\"Number of Rows - Final dataset: {n_rows_final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433c56b-d689-47f5-9909-fef27f4ccb77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.4 Rating Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc304d-8f56-4051-815d-49ff13645eb9",
   "metadata": {},
   "source": [
    "We want to calculate the overall average score to see if consistency is maintained after creating the subsample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d55063-645d-49bf-a292-18707abbb343",
   "metadata": {},
   "source": [
    "- Overall mean score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "165372fe-dcaa-47ce-a264-3bbf09c6d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean score: 4.22386130919595\n"
     ]
    }
   ],
   "source": [
    "df_final = df_final.withColumn(\"mean_score\", F.col(\"mean_score\").cast(\"double\"))\n",
    "\n",
    "overall_mean = df_final.agg(F.avg(\"mean_score\")).collect()[0][0]\n",
    "print(f\"Overall mean score - Final dataset: {overall_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacaa7a-69df-4f0f-b974-35e01a859238",
   "metadata": {},
   "source": [
    "- Mean score for each item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29ae5ae6-01ef-4f19-a09e-67c65d13c94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|        Id|avg_score_pre|\n",
      "+----------+-------------+\n",
      "|0027861317|        4.625|\n",
      "|0028622480|          4.0|\n",
      "|0029267358|          4.0|\n",
      "|0060929081|         4.24|\n",
      "|0071409807|         3.75|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_per_id = df_final.groupBy(\"Id\").agg(F.avg(\"mean_score\").alias(\"avg_score_pre\"))\n",
    "score_per_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1f45fa9-1ac1-4e42-a7d9-61c358cfc9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| Id|avg_score_pre|\n",
      "+---+-------------+\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data integrity\n",
    "score_per_id_above_5 = score_per_id.filter(F.col(\"avg_score_pre\") > 5)\n",
    "\n",
    "score_per_id_above_5.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ea9f6-42b3-4586-ae5a-f06239029d1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "### 3. Subsample Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1a154fe-0311-486e-94e3-3ecaa4f37431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep 10% of original data\n",
    "# df_subsample = df_final.sample(withReplacement=False, fraction=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "303c546b-8e54-45e4-8310-1c9475d07c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows - Subsample: 237713\n"
     ]
    }
   ],
   "source": [
    "#n_rows_subsample = df_subsample.count()\n",
    "#print(f\"Number of Rows - Subsample: {n_rows_subsample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "861bd5be-304b-4408-9371-db939d14a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- mean_score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data integrity\n",
    "#df_subsample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaf3dcce-ecfa-442c-a517-521a8130c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_subsample = df_subsample.withColumn(\"mean_score\", F.col(\"mean_score\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71668d-003b-4fbc-96dd-6efb20d34879",
   "metadata": {},
   "source": [
    "- Overall mean score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3729103e-420b-49c6-a444-1523dbfee40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean sample: 4.227572745285281\n"
     ]
    }
   ],
   "source": [
    "#overall_mean_sample = df_subsample.agg(F.avg(\"mean_score\")).collect()[0][0]\n",
    "#print(f\"Overall mean sample: {overall_mean_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4993d5-3042-401e-ac9d-4b7e61a1e99c",
   "metadata": {},
   "source": [
    "It's coherent with the already computed mean (before subsample creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24e24092-a758-4330-bcea-65cce066e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21056f28-3e8c-44f4-a835-609c111f028b",
   "metadata": {},
   "source": [
    "We aim to create a subsample that remains consistent with the original dataset. To achieve this, we select a fraction of users while ensuring that all their reviews are included. This approach allows us to better represent their purchasing behavior and rating patterns, preserving the integrity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1f2591d-06d3-4f9c-a6ee-06f4103590a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di utenti unici: 1004214\n"
     ]
    }
   ],
   "source": [
    "num_users = df_final.select(\"User_id\").distinct().count()\n",
    "print(f\"Total number of different users - Original dataset: {num_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94cee6f8-b6c5-4a3b-a5f8-4caffdd9f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep just 20% of the users\n",
    "sample_fraction = 0.2\n",
    "user_sample = df_final.select(\"User_id\").distinct().sample(fraction=sample_fraction, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b97d58b5-6af5-43c1-9aa7-7f5651c51363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+\n",
      "|             User_id|        Id|mean_score|\n",
      "+--------------------+----------+----------+\n",
      "|A00891092QIVH4W1Y...|0134354575|       2.0|\n",
      "|A00891092QIVH4W1Y...|0395051029|       2.0|\n",
      "|A00891092QIVH4W1Y...|1582790337|       2.0|\n",
      "|A00891092QIVH4W1Y...|B000P4Q3JS|       2.0|\n",
      "|A00891092QIVH4W1Y...|0140860282|       2.0|\n",
      "+--------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the subsample with the selected users\n",
    "df_sampled = df_final.join(user_sample, on=\"user_id\", how=\"inner\")\n",
    "df_sampled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f48b9e1-b2f5-4014-91ef-2f1308b39929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows - Sample: 471573\n"
     ]
    }
   ],
   "source": [
    "# Check subsample size\n",
    "n_rows_sample = df_sampled.count()\n",
    "print(f\"Number of Rows - Sample: {n_rows_sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0869e35a-d2c5-4a99-b25f-dfd385438b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_id: string (nullable = true)\n",
      " |-- Id: string (nullable = true)\n",
      " |-- mean_score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data integrity\n",
    "df_sampled.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc93f259-0a98-47bd-99d6-5510a467fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean sample: 4.221354205322752\n"
     ]
    }
   ],
   "source": [
    "# Check mean coherence with the original dataset\n",
    "overall_mean_sample = df_sampled.agg(F.avg(\"mean_score\")).collect()[0][0]\n",
    "print(f\"Overall mean - Sample: {overall_mean_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3291f-03c3-43fe-9f01-2a27374cf616",
   "metadata": {},
   "source": [
    "The overall mean of the subsample is coherent with the overall mean of the original final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4bba1-1e78-4823-9144-166150aa1e88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "### 4. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fb0b5-2198-4670-b2cd-84e837a39801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
